"""
自然语言处理的发展历程
"""

# 【计算机博物志】自然语言处理的“古往”和“今来”】 https://www.bilibili.com/video/BV1yi4y1B7Jt/?share_source=copy_web&vd_source=eedb836b20e30caf77faad19f967cda0

# 语音识别的早期技术（2009年之前）
# 主要技术基础：隐马尔可夫模型（HMM）
# 应用背景：HMM用于模拟语音信号中声音的统计特性，实现声音与文字之间的概率模型识别。
# 技术局限：虽然一度是主流技术，但随着技术进步，其性能逐渐不能满足更高的准确性和效率需求。

# 深度学习技术的兴起（2006年以来）
# 关键技术进步：深度学习和神经网络，尤其是深度神经网络（DNNs）、卷积神经网络（CNNs）、循环神经网络（RNNs）的发展。
# 应用变革：自2009年起，得益于硬件计算能力的提升和大规模数据集的可用性，这些技术开始大规模应用于语音识别，标志着从传统统计方法向基于深度学习方法的转变。
# 成果体现：深度学习方法大大提高了语音识别的准确性和效率，推动了语音识别技术的广泛应用。

# 关键技术和模型
# word2vec（2013年）：谷歌提出的一种高效的预训练词向量模型。
# Transformer（2017年）：引入了自注意力机制，成为后续许多NLP模型的基础架构。
# 注意力机制（Attention）：一种提高模型对输入数据不同部分重要性判断能力的技术，Transformer模型的核心。
# 循环神经网络（RNNs）：特别适合处理序列数据，如文本和语音，对早期的NLP任务有重要贡献。
# GPT：基于Transformer的大规模预训练语言模型，推动了NLP领域的许多应用和研究。

# 深度学习概论（待补充）
# 这里可以补充关于深度学习的基本概念，包括但不限于深度学习的定义、关键技术特点、在自然语言处理中的应用示例，以及它如何改变了NLP的研究和应用领域。

"""
深度学习概论
"""

# 培训班课程 20230704 深度学习概述讲解 126, 127

# 深度学习概述总结

# 1. 深度学习应用
# 深度学习在多个领域中找到了应用，包括但不限于图像识别、语音识别、自然语言处理、机器翻译、医疗诊断、
# 无人驾驶车辆、游戏玩法、新药发现、目标检测、图像分割、图像生成、推荐系统、搜索系统、聊天机器人、文本检索系统。这些应用展示了深度学习模型在从大量数据中学习复杂表示、捕捉细微模式方面的强大能力。

# 2. 神经网络在深度学习中的作用
# 神经网络是深度学习的核心，模仿人脑处理信息的方式，由大量互相连接的节点（神经元）组成。
# 这些网络能够通过调整节点间连接的权重来学习输入数据的复杂非线性关系。

# 3. 多项式扩展与深度学习的联系
# 多项式扩展通过增加模型的复杂性来提高其非线性拟合能力，类似地，深度学习通过堆叠多个非线性层来实现更复杂的功能表示，增强模型的表达能力。

# 4. 深度学习就是LR（Logistic Regression，逻辑回归）的堆叠的理解
# 将深度学习视为逻辑回归模型的堆叠有助于理解其基本概念，其中每一层的输出可以被视为对前一层输入的逻辑回归变换。这个简化视图有助于理解深度网络如何通过重复的非线性变换学习复杂关系，虽然实际上深度学习模型的结构要复杂得多。

# 5. 感知器模型、SoftMax、多层感知机、感知器网络S神经元，激活函数之间的联系和拓展
# 感知器模型是最简单的神经网络，仅包含输入和输出层，能执行简单二分类任务。多层感知机（MLP）通过引入一个或多个隐藏层来捕捉复杂的非线性关系，其中每个隐藏层的节点可以使用不同的激活函数（如Sigmoid、ReLU）来增加模型的非线性。SoftMax函数常用于多分类任务的输出层，将神经网络的输出转换为概率分布。这些概念共同构成了深度学习模型的基础，使其能够学习从简单到复杂的数据表示。

# 6. 神经网络结构
# 神经网络的基本结构包括输入层、一个或多个隐藏层和输出层。网络的复杂性可以通过增加隐藏层的数量和每层中的神经元数量来调整，不同的结构配置适用于不同的任务和数据类型。

# 7. 深层神经网络（DNN）
# 深层神经网络通过增加网络的深度（即隐藏层的数量）来提高学习能力，而不仅仅是增加网络的宽度（单层中的神经元数量）。这使得DNN能够进行更复杂的特征抽象和数据表示，为现代深度学习应用提供了基础。
